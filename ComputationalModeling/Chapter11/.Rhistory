h <- 60
f <- 11
sigtrials <- noistrials <- 100
gmix <- 0.2
N <- 20000
##------ SDT
# specify function to enter in to importance sampling mixture
# here we use the prior distributions
d <- rnorm(N, mean=1, sd=1) #* \label{line:importp1}  *\#
B <- rnorm(N, mean=0, sd=1)
df <- function(x) dnorm(x,1,1)
dB <- function(x) dnorm(x,0,1) #* \label{line:importp4}  *\#
# obtain samples from posterior
source("SDT.R")
mcmcs <- as.matrix(mcmcfin)
d_mu <- mean(mcmcs[,"d"]) #* \label{line:isfitting1}  *\#
d_sd <- sd(mcmcs[,"d"])
B_mu <- mean(mcmcs[,"b"])
B_sd <- sd(mcmcs[,"b"]) #* \label{line:isfitting2}  *\#
d_pos <- rnorm(N, mean=d_mu,sd=d_sd) #* \label{line:importSamplePos}  *\#
B_pos <- rnorm(N, mean=B_mu,sd=B_sd)
mask <- runif(N)>gmix
d[mask] <- d_pos[mask]
B[mask] <- B_pos[mask]
pp <- dnorm(d,1,1)*
dnorm(B,0,1)/
((1-gmix)*dnorm(d,d_mu,d_sd)*dnorm(B,B_mu,B_sd) + gmix*df(d)*dB(B))
L <- dbinom(h,sigtrials,pnorm(d/2-B))*
dbinom(f,noistrials,pnorm(-d/2-B))*pp
ml_SDT <- mean(L)
# ---------1HT (beta)
# specify function to enter in to importance sampling mixture with the posterior
# here we use the prior distributions
th1 <- rbeta(N, 1, 1)
th2 <- rbeta(N, 1, 1)
d1 <- function(x) dbeta(x,1,1)
d2 <- function(x) dbeta(x,1,1)
## obtain samples from posterior
source("1HT.R")
mcmcs <- as.matrix(mcmcfin)
#obtain beta parameter estimates using MLE
kk <- fitdistr(mcmcs[,"th1"], "beta", list(shape1=5,shape2=5))
th1_s1 <- kk$estimate[1]
th1_s2 <- kk$estimate[2]
kk <- fitdistr(mcmcs[,"th2"], "beta", list(shape1=5,shape2=5))
th2_s1 <- kk$estimate[1]
th2_s2 <- kk$estimate[2]
th1_pos <- rbeta(N, th1_s1,th1_s2)
th2_pos <- rbeta(N, th2_s1,th2_s2)
mask <- runif(N)>gmix
th1[mask] <- th1_pos[mask]
th2[mask] <- th2_pos[mask]
pp <- dbeta(th1,1,1)*
dbeta(th2,1,1)/
((1-gmix)*dbeta(th1,th1_s1,th1_s2)*dbeta(th2,th2_s1,th2_s2) + gmix*d1(th1)*d2(th2))
L <- dbinom(h,sigtrials,th1+(1-th1)*th2) *
dbinom(f,noistrials,th2)*pp
ml_HT <- mean(L)
#---What is the Bayes Factor?
ml_SDT/ml_HT
library(logspline)
source("SDT_small.R")
mcmcs <- as.matrix(mcmcfin)
blogspl <- logspline(mcmcs[,"b"])
BF <- dlogspline(0,blogspl)/dnorm(0,0,1)
print(BF)
#pdf(file="SavageD.pdf", width=5, height = 5)
x <- seq(-0.25,0.25,length.out = 1000)
priy <- dnorm(x,0,1)
posy <- dlogspline(x, blogspl)
matplot(x, cbind(priy,posy), type="l",
xlab="b", ylab="Prob Density", lwd=2)
legend(-0.2,1,legend=c("Prior","Posterior"), lty=1:2, col=1:2, lwd=2)
points(0, dnorm(0,0,1)); text(0.015, dnorm(0,0,1)+0.05, "p(b=0|H1)")
points(0, dlogspline(0, blogspl)); text(0.05, dlogspline(0, blogspl)-0.05, "p(b=0|y,H1)")
#dev.off()
SDT_ll <- function(d,B,h,f,sigtrials,noistrials){ #* \label{line:beginMaxLikH0}  *\#
return(-2*(
log(dbinom(h,sigtrials,pnorm(d/2-B)))+
log(dbinom(f,noistrials,pnorm(-d/2-B)))
))
}
llgen <- optim(c(1,0),function(x) SDT_ll(x[1],x[2],h,f,sigtrials,noistrials))
llspec <- optim(1,function(x) SDT_ll(x[1],0,h,f,sigtrials,noistrials),
method="Brent",lower=-5,upper=5)
chi2diff <- llspec$value - llgen$value
print(chi2diff);print(1-pchisq(chi2diff,1)) #* \label{line:endMaxLikH0}  *\#
library (rjags)
library(MASS)
tlags <- c(0, 1, 5, 10, 20, 50)
nlags <- length(tlags)
nitems <- 40
nrecalled <- rep(0,nlags)
a <- 0.1
b <- .95
alpha <- .2
# simulate data
for (j in 1:nlags) {
p <- a + (1-a) * b * exp(-alpha*tlags[j])
nrecalled[j] <- rbinom(1,nitems,p)
}
#plot(tlags,nrecalled)
a1.s1<-{}; a1.s2<-{}; a2.s1<-{}; a2.s2<-{}
b1.s1<-{}; b1.s2<-{}; b2.s1<-{}; b2.s2<-{}
alpha.s1<-{}; alpha.s2<-{}; beta.s1<-{}; beta.s2<-{}
###---- Prior parameters
## Model 1 (exponential)
# priors
a1.s1[1] <- 1; a1.s2[1]<- 1
b1.s1[1] <- 1; b1.s2[1]<- 1
alpha.s1[1] <- 1; alpha.s2[1] <- 1
# psuedo-priors--set these to priors for the moment
a1.s1[2] <- 1; a1.s2[2]<- 1
b1.s1[2] <- 1; b1.s2[2]<- 1
alpha.s1[2] <- 1; alpha.s2[2] <- 1
## Model 2 (power)
# priors
a2.s1[2] <- 1; a2.s2[2]<- 1
b2.s1[2] <- 1; b2.s2[2]<- 1
beta.s1[2] <- 1; beta.s2[2] <- 1
# psuedo-priors (temporary)
a2.s1[1] <- 1; a2.s2[1]<- 1
b2.s1[1] <- 1; b2.s2[1]<- 1
beta.s1[1] <- 1; beta.s2[1] <- 1
# ------------Estimate exponential only
expmod <- jags.model("powerexp.j",
data = list(t  = tlags,
k = nrecalled,
n  = nitems,
nt = nlags,
a1.s1 = a1.s1, a1.s2 = a1.s2,
a2.s1 = a2.s1, a2.s2 = a2.s2,
b1.s1 = b1.s1, b1.s2 = b1.s2,
b2.s1 = b2.s1, b2.s2 = b2.s2,
alpha.s1 = alpha.s1, alpha.s2=alpha.s2,
beta.s1 = beta.s1, beta.s2=beta.s2,
prior1 = 1),
n.chains=4)
# burnin
update(expmod,n.iter=1000)
# perform MCMC
parameters <- c("a1", "b1", "alpha")
mcmcfin<-coda.samples(expmod,parameters,5000)
mm <- as.matrix(mcmcfin)
# set pseudo-priors to approximate posterior
a1fit <- fitdistr(mm[,"a1"],"beta",start=list(shape1=1,shape2=1))$estimate
b1fit <- fitdistr(mm[,"b1"],"beta",start=list(shape1=1,shape2=1))$estimate
alphafit <- fitdistr(mm[,"alpha"],"beta",start=list(shape1=1,shape2=1))$estimate
a1.s1[2] <- a1fit[1]; a1.s2[2]<- a1fit[2]
b1.s1[2] <- b1fit[1]; b1.s2[2]<- b1fit[2]
alpha.s1[2] <- alphafit[1]; alpha.s2[2] <- alphafit[2]
# ------------Estimate powerl only
expmod <- jags.model("powerexp.j",
data = list(t  = tlags,
k = nrecalled,
n  = nitems,
nt = nlags,
a1.s1 = a1.s1, a1.s2 = a1.s2,
a2.s1 = a2.s1, a2.s2 = a2.s2,
b1.s1 = b1.s1, b1.s2 = b1.s2,
b2.s1 = b2.s1, b2.s2 = b2.s2,
alpha.s1 = alpha.s1, alpha.s2=alpha.s2,
beta.s1 = beta.s1, beta.s2=beta.s2,
prior1 = 0),
n.chains=4)
# burnin
update(expmod,n.iter=1000)
# perform MCMC
parameters <- c("a2", "b2", "beta")
mcmcfin<-coda.samples(expmod,parameters,5000)
mm <- as.matrix(mcmcfin)
# set pseudo-priors to approximate posterior
a2fit <- fitdistr(mm[,"a2"],"beta",start=list(shape1=1,shape2=1))$estimate #* \label{line:BF:usePseudos}  *\#
b2fit <- fitdistr(mm[,"b2"],"beta",start=list(shape1=1,shape2=1))$estimate
betafit <- fitdistr(mm[,"beta"],"beta",start=list(shape1=1,shape2=1))$estimate
a2.s1[1] <- a2fit[1]; a2.s2[1]<- a2fit[2]
b2.s1[1] <- b2fit[1]; b2.s2[1]<- b2fit[2]
beta.s1[1] <- betafit[1]; beta.s2[1] <- betafit[2]
# ------------Estimate pM2
prior1 <- 0.2 # this value affects the mixing, should approximate 1/posterior
expmod <- jags.model("powerexp.j",
data = list(t  = tlags,
k = nrecalled,
n  = nitems,
nt = nlags,
a1.s1 = a1.s1, a1.s2 = a1.s2,
a2.s1 = a2.s1, a2.s2 = a2.s2,
b1.s1 = b1.s1, b1.s2 = b1.s2,
b2.s1 = b2.s1, b2.s2 = b2.s2,
alpha.s1 = alpha.s1, alpha.s2=alpha.s2,
beta.s1 = beta.s1, beta.s2=beta.s2,
prior1 = prior1),
n.chains=4)
# burnin
update(expmod,n.iter=1000)
# perform MCMC
parameters <- c("alpha","beta","theta","pM2")
mcmcfin<-coda.samples(expmod,parameters,10000, thin=1)
#summary(mcmcfin)
mm <- as.matrix(mcmcfin)
post2 <- mean(as.matrix(mcmcfin)[,"pM2"]) #* \label{line:PSposteriorcalc}  *\#
print((1-post2)/post2*(1-prior1)/prior1)
# plot acf
myacf <- {}
for (chain in 1:4){
myacf <- cbind(myacf, acf(mcmcfin[[chain]][,"pM2"], lag.max=30, plot=F)$acf)
}
matplot(0:10, myacf[1:11,], type="l",
xlab="Lag",ylab="Autocorrelation",ylim=c(0,1))
# ------------Numerical Estimation of marginal L for comparison
library(cubature)
expL <- function(theta,tlags,y,n){
a <- theta[1]
b <- theta[2]
alpha <- theta[3]
p <- dbinom(y,n,a+(1-a)*b*exp(-alpha*tlags))
return(prod(p))
}
powL <- function(theta,tlags,y,n){
a <- theta[1]
b <- theta[2]
beta <- theta[3]
p <- dbinom(y,n,a+(1-a)*b*((tlags+1)^(-beta)))
return(prod(p))
}
expML <- adaptIntegrate(expL,c(0,0,0),c(0.2,1,1),
tlags=tlags,y=nrecalled,n=nitems)
powML <- adaptIntegrate(powL,c(0,0,0),c(0.2,1,1),
tlags=tlags,y=nrecalled,n=nitems)
expML$integral/powML$integral
library (rjags)
library(MASS)
tlags <- c(0, 1, 5, 10, 20, 50)
nlags <- length(tlags)
nitems <- 40
nrecalled <- rep(0,nlags)
a <- 0.1
b <- .95
alpha <- .2
# simulate data
for (j in 1:nlags) {
p <- a + (1-a) * b * exp(-alpha*tlags[j])
nrecalled[j] <- rbinom(1,nitems,p)
}
#plot(tlags,nrecalled)
a1.s1<-{}; a1.s2<-{}; a2.s1<-{}; a2.s2<-{}
b1.s1<-{}; b1.s2<-{}; b2.s1<-{}; b2.s2<-{}
alpha.s1<-{}; alpha.s2<-{}; beta.s1<-{}; beta.s2<-{}
###---- Prior parameters
## Model 1 (exponential)
# priors
a1.s1[1] <- 1; a1.s2[1]<- 1
b1.s1[1] <- 1; b1.s2[1]<- 1
alpha.s1[1] <- 1; alpha.s2[1] <- 1
# psuedo-priors--set these to priors for the moment
a1.s1[2] <- 1; a1.s2[2]<- 1
b1.s1[2] <- 1; b1.s2[2]<- 1
alpha.s1[2] <- 1; alpha.s2[2] <- 1
## Model 2 (power)
# priors
a2.s1[2] <- 1; a2.s2[2]<- 1
b2.s1[2] <- 1; b2.s2[2]<- 1
beta.s1[2] <- 1; beta.s2[2] <- 1
# psuedo-priors (temporary)
a2.s1[1] <- 1; a2.s2[1]<- 1
b2.s1[1] <- 1; b2.s2[1]<- 1
beta.s1[1] <- 1; beta.s2[1] <- 1
# ------------Estimate exponential only
expmod <- jags.model("powerexp.j",
data = list(t  = tlags,
k = nrecalled,
n  = nitems,
nt = nlags,
a1.s1 = a1.s1, a1.s2 = a1.s2,
a2.s1 = a2.s1, a2.s2 = a2.s2,
b1.s1 = b1.s1, b1.s2 = b1.s2,
b2.s1 = b2.s1, b2.s2 = b2.s2,
alpha.s1 = alpha.s1, alpha.s2=alpha.s2,
beta.s1 = beta.s1, beta.s2=beta.s2,
prior1 = 1),
n.chains=4)
# burnin
update(expmod,n.iter=1000)
# perform MCMC
parameters <- c("a1", "b1", "alpha")
mcmcfin<-coda.samples(expmod,parameters,5000)
mm <- as.matrix(mcmcfin)
# set pseudo-priors to approximate posterior
a1fit <- fitdistr(mm[,"a1"],"beta",start=list(shape1=1,shape2=1))$estimate
b1fit <- fitdistr(mm[,"b1"],"beta",start=list(shape1=1,shape2=1))$estimate
alphafit <- fitdistr(mm[,"alpha"],"beta",start=list(shape1=1,shape2=1))$estimate
a1.s1[2] <- a1fit[1]; a1.s2[2]<- a1fit[2]
b1.s1[2] <- b1fit[1]; b1.s2[2]<- b1fit[2]
alpha.s1[2] <- alphafit[1]; alpha.s2[2] <- alphafit[2]
library (rjags)
library(MASS)
tlags <- c(0, 1, 5, 10, 20, 50)
nlags <- length(tlags)
nitems <- 40
nrecalled <- rep(0,nlags)
a <- 0.1
b <- .95
alpha <- .2
# simulate data
for (j in 1:nlags) {
p <- a + (1-a) * b * exp(-alpha*tlags[j])
nrecalled[j] <- rbinom(1,nitems,p)
}
#plot(tlags,nrecalled)
a1.s1<-{}; a1.s2<-{}; a2.s1<-{}; a2.s2<-{}
b1.s1<-{}; b1.s2<-{}; b2.s1<-{}; b2.s2<-{}
alpha.s1<-{}; alpha.s2<-{}; beta.s1<-{}; beta.s2<-{}
###---- Prior parameters
## Model 1 (exponential)
# priors
a1.s1[1] <- 1; a1.s2[1]<- 1
b1.s1[1] <- 1; b1.s2[1]<- 1
alpha.s1[1] <- 1; alpha.s2[1] <- 1
# psuedo-priors--set these to priors for the moment
a1.s1[2] <- 1; a1.s2[2]<- 1
b1.s1[2] <- 1; b1.s2[2]<- 1
alpha.s1[2] <- 1; alpha.s2[2] <- 1
## Model 2 (power)
# priors
a2.s1[2] <- 1; a2.s2[2]<- 1
b2.s1[2] <- 1; b2.s2[2]<- 1
beta.s1[2] <- 1; beta.s2[2] <- 1
# psuedo-priors (temporary)
a2.s1[1] <- 1; a2.s2[1]<- 1
b2.s1[1] <- 1; b2.s2[1]<- 1
beta.s1[1] <- 1; beta.s2[1] <- 1
# ------------Estimate exponential only
expmod <- jags.model("powerexp.j",
data = list(t  = tlags,
k = nrecalled,
n  = nitems,
nt = nlags,
a1.s1 = a1.s1, a1.s2 = a1.s2,
a2.s1 = a2.s1, a2.s2 = a2.s2,
b1.s1 = b1.s1, b1.s2 = b1.s2,
b2.s1 = b2.s1, b2.s2 = b2.s2,
alpha.s1 = alpha.s1, alpha.s2=alpha.s2,
beta.s1 = beta.s1, beta.s2=beta.s2,
prior1 = 1),
n.chains=4)
# burnin
update(expmod,n.iter=1000)
# perform MCMC
parameters <- c("a1", "b1", "alpha")
mcmcfin<-coda.samples(expmod,parameters,5000)
mm <- as.matrix(mcmcfin)
# set pseudo-priors to approximate posterior
a1fit <- fitdistr(mm[,"a1"],"beta",start=list(shape1=1,shape2=1))$estimate
b1fit <- fitdistr(mm[,"b1"],"beta",start=list(shape1=1,shape2=1))$estimate
alphafit <- fitdistr(mm[,"alpha"],"beta",start=list(shape1=1,shape2=1))$estimate
a1.s1[2] <- a1fit[1]; a1.s2[2]<- a1fit[2]
b1.s1[2] <- b1fit[1]; b1.s2[2]<- b1fit[2]
alpha.s1[2] <- alphafit[1]; alpha.s2[2] <- alphafit[2]
# ------------Estimate powerl only
expmod <- jags.model("powerexp.j",
data = list(t  = tlags,
k = nrecalled,
n  = nitems,
nt = nlags,
a1.s1 = a1.s1, a1.s2 = a1.s2,
a2.s1 = a2.s1, a2.s2 = a2.s2,
b1.s1 = b1.s1, b1.s2 = b1.s2,
b2.s1 = b2.s1, b2.s2 = b2.s2,
alpha.s1 = alpha.s1, alpha.s2=alpha.s2,
beta.s1 = beta.s1, beta.s2=beta.s2,
prior1 = 0),
n.chains=4)
# burnin
update(expmod,n.iter=1000)
# perform MCMC
parameters <- c("a2", "b2", "beta")
mcmcfin<-coda.samples(expmod,parameters,5000)
mm <- as.matrix(mcmcfin)
# set pseudo-priors to approximate posterior
a2fit <- fitdistr(mm[,"a2"],"beta",start=list(shape1=1,shape2=1))$estimate #* \label{line:BF:usePseudos}  *\#
b2fit <- fitdistr(mm[,"b2"],"beta",start=list(shape1=1,shape2=1))$estimate
betafit <- fitdistr(mm[,"beta"],"beta",start=list(shape1=1,shape2=1))$estimate
a2.s1[1] <- a2fit[1]; a2.s2[1]<- a2fit[2]
b2.s1[1] <- b2fit[1]; b2.s2[1]<- b2fit[2]
beta.s1[1] <- betafit[1]; beta.s2[1] <- betafit[2]
#next line must be L5
library(rjags)
#simulate data from experiment with 10 subjects
n <- 10
sigtrials <- noistrials <- 100
h <- rbinom(n,sigtrials, .8)
f <- rbinom(n,noistrials,.2)
#f[10]<- 80
#h[10]<- 20
#initialize for JAGS
# top priors
mud_p <- c(1,1/(2^2))
mub_p <- c(0,1/(2^2))
taud_p <- c(.001,.001)
taub_p <- c(.001,.001)
oneinit <- list(mud=0, mub=0, taud=1, taub=1, d=rep(0,n), b=rep(0,n))
myinits <- list(oneinit)[rep(1,4)]
sdtjh <- jags.model("SDThierarch.j",
data = list("h"=h, "f"=f, "n"=n,
mud_p=mud_p,mub_p=mub_p,
taud_p=taud_p,taub_p=taub_p,
"sigtrials" =sigtrials,
"noistrials"=noistrials),
inits=myinits,
n.chains=4)
library(rjags)
#provide data from experiment
h <- 12
f <- 2
sigtrials <- noistrials <- 20
#initialize for JAGS
oneinit <- list(d=0, b=0)
myinits <- list(oneinit)[rep(1,4)]
sdtj <- jags.model("SDT.j",
data = list("h"=h, "f"=f,
"sigtrials"=sigtrials,
"noistrials"=noistrials),
inits=myinits,
n.chains=4)
# burnin
update(sdtj,n.iter=1000)
# perform MCMC
parameters <- c("d", "b", "phih", "phif")
mcmcfin<-coda.samples(sdtj,parameters,5000)
theta <- seq(0,1,length.out = 100)
y <- seq(0,1,length.out = 100)
z <- matrix(rep(0,100*100),nrow=100)
#pdf(file="BayesOccam.pdf", width=8, height=8)
par(mfrow=c(2,2))
for (tt in 1:100){
for (ty in 1:100){
z[tt,ty] <- dnorm(y[ty], mean=theta[tt], sd=0.1)
}
}
image(z, col= gray(seq(1,0.5,length.out = 1000)),
xlab=expression(theta), ylab="y")
abline(0.5,0, lty=1, lwd=2); text(0.1, 0.4, "y=0.5")
abline(0.8,0, lty=2, lwd=2); text(0.1, 0.7, "y=0.8")
title("Complex Model")
for (tt in 1:100){
for (ty in 1:100){
z[tt,ty] <- dnorm(y[ty], mean=0.5, sd=0.1)
}
}
image(z, col= gray(seq(1,0.5,length.out = 1000)),
xlab=expression(theta), ylab="y")
abline(0.5,0, lty=1, lwd=2); text(0.1, 0.4, "y=0.5")
abline(0.8,0, lty=2, lwd=2); text(0.1, 0.7, "y=0.8")
title("Simple Model")
yy <- cbind(dnorm(0.5, mean=theta, sd=0.1),dnorm(0.8, mean=theta, sd=0.1))
#ylab=paste("p(y|", expression(theta), ")"))
matplot(theta, yy, type="l", lty=1:2, xlab=expression(theta),col=1,
ylab=expression(paste("p(y|")* theta * "," * M[complex] * ")"),
ylim=c(0,5))
yy <- cbind(dnorm(0.5, mean=rep(0.5,100), sd=0.1),dnorm(0.8, mean=rep(0.5,100), sd=0.1))
#ylab=paste("p(y|", expression(theta), ")"))
matplot(theta, yy, type="l", lty=1:2, xlab=expression(theta),col=1,
ylab=expression(paste("p(y|")* theta * "," * M[simple] * ")"),
ylim=c(0,5))
legend(0,3,lty=1:2, col=1, c("y=0.5","y=0.8"), text.width = 0.2)
#dev.off()
library(rjags)
#provide data from experiment
h <- 12
f <- 2
sigtrials <- noistrials <- 20
#initialize for JAGS
oneinit <- list(d=0, b=0)
myinits <- list(oneinit)[rep(1,4)]
sdtj <- jags.model("SDT.j",
data = list("h"=h, "f"=f,
"sigtrials"=sigtrials,
"noistrials"=noistrials),
inits=myinits,
n.chains=4)
# burnin
update(sdtj,n.iter=1000)
# perform MCMC
parameters <- c("d", "b", "phih", "phif")
mcmcfin<-coda.samples(sdtj,parameters,5000)
stim <- list(c(1,-1,1,-1),
c(1,1,1,1))
resp <- list(c(1,1,-1,-1),
c(1,-1,-1,1))
n <- 4 # number of input units
m <- 4 # number of output units
W <- matrix(rep(0,m*n), nrow=m)
alpha <- 0.25
# Learning
for (pair in 1:2){ # store association for each pair
for (i in 1:m){ # loop across output units
for (j in 1:n){ # loop across input units
W[i,j] <- W[i,j] + alpha*stim[[pair]][j]*resp[[pair]][i] #* \label{line:NeuralNetworks:simpleLearn}  *\#
}
}
}
# Learning 2
W2 <- resp[[1]]%*%t(stim[[1]]) + resp[[2]] %*% t(stim[[2]])
# Test phase; test with first stimulus
o <- rep(0,m) #* \label{line:NeuralNetworks:simpleInitOut}  *\#
for (i in 1:m){
for (j in 1:n){
o[i] <- o[i] + W[i,j]*stim[[1]][j]
}
}
library(lsa)
cosine(o,resp[[1]])
