jp4prop <- function(p) {p^-0.5 * (1-p)^-0.5}
#get overall prior for model parameters
logprior<- function(g,sdv) {
return(log(jp4kappa(sd2k(sdv)))+log(jp4prop(g)))
}
#make it circular in degrees
mkcirc<-function(td)
{as.circular(td,control.circular=list(units="degrees"))}
#previous line must be 39
#main function that fits mixture model to data being passed as argument
#next line must be 43
getMixtmodel <-function(data,svalues) {
chain <- matrix(0,5000,2)
burnin<-500
set.seed(1234)
propsd <- svalues*.05
lb <- c(0,4)
ub <- c(1,360)
chain[1,] <- svalues #starting values for parameters
for (i in c(2:dim(chain)[1])) {
cur <- chain[i-1,]
doitagain <- TRUE
while (doitagain) {
propl <- cur + rnorm(2,0,propsd)
doitagain <- any(propl<lb) || any(propl>ub)
}
lpropval <- logmixturepdf(data,propl[1],propl[2])
+logprior(propl[1],propl[2])
lcurval  <- logmixturepdf(data,cur[1],cur[2])
+logprior(cur[1],cur[2])
llratio  <- exp(lpropval-lcurval)
if (runif(1) < llratio) {
chain[i,] <- propl
} else {
chain[i,] <- cur
}
}
finparm<-apply(chain[-c(1:burnin),],2,mean)
print(finparm)
td<-c(-180:180)
pred<-(1-finparm[1])*
dvonmises(mkcirc(td),mkcirc(0),sd2k(finparm[2]))+
finparm[1]*dunif(td,-180,180)
posterior<-chain[-c(1:burnin),]
return(list(preds=pred,posteriors=posterior))
}
install.packages("ggplot2")
install.packages("mixtools")
library(rjags)
#provide data from experiment
h <- 60
f <- 11
sigtrials <- noistrials <- 100
#define JAGS model
onehtj <- jags.model("1HT.j",
data = list("h"=h, "f"=f,
"sigtrials"=sigtrials,
"noistrials"=noistrials),
n.chains=4)
require(mvtnorm)
require(mvtnorm)
require(MASS)
nsamples <- 1000
rho <- .8
mux  <- muy <- 0
sigx <- 1
sigy <- .5
sigma <- matrix(c(sigx^2,rho*sigx*sigy,rho*sigy*sigx,sigy^2),
nrow=2)
#draw contour plot of known distribution
fiftyticks <- seq(from=-3, to =3, length.out=50)
y<-rep(fiftyticks,50)
x<-rep(fiftyticks,each=50)
z<-matrix( dmvnorm(cbind(y,x),c(mux,muy),sigma),50,50)
contour(list(x=fiftyticks,y=fiftyticks,z=z),
ylim=c(-3,3),xlim=c(-3,3),drawlabels=FALSE)
#gibbs sampling
sxt1mr <- sqrt(sigx^2*(1-rho^2))
syt1mr <- sqrt(sigy^2*(1-rho^2))
rxy <- rho*(sigx/sigy)
ryx <- rho*(sigy/sigx)
xsamp <- ysamp <- rep(0,nsamples)
xsamp[1] <- -2
ysamp[1] <- 2
for (i in c(1:(nsamples-1))) {
xsamp[i+1] <- rnorm(1, mean=rxy*ysamp[i], sd=sxt1mr)
ysamp[i+1] <- rnorm(1, mean=ryx*xsamp[i+1], sd=syt1mr)
}
points(xsamp[-c(1:500)],ysamp[-c(1:500)],pch=21,bg="red")
for (j in c(1:5)){
points(xsamp[j],ysamp[j]-.005,pch=21,cex=3.5,bg="white")
text(xsamp[j],ysamp[j],as.character(j))
}
cor.test(xsamp,ysamp)
sd(xsamp)
sd(ysamp)
bivn<-rmvnorm(1000,rep(0,2),sigma)
#some checks
apply(bivn,2,mean)
apply(bivn,2,sd)
cor.test(bivn[,1],bivn[,2])
# Load the necessary library
library(dplyr)
# Ignore warnings
#options(warn = -1)
# Parameters
target <- "ComputationalModeling"
base_dir_path <- "/Users/seojin/Desktop/ComputationalCognitiveModeling"
test_code_dir_path <- "/Users/seojin/Desktop/ComputationalCognitiveModeling/TestCodes"
dir_path <- paste0(base_dir_path, "/", target)
log_file_path <- paste0(test_code_dir_path, "/" , paste0(target, "_log.txt"))
checked_source_path <- paste0(test_code_dir_path, "/" , paste0(target, "_checked.csv"))
plot_dir_path <- paste0(test_code_dir_path, "/" , target)
# Log
file.remove(log_file_path)
writeLines("Start testing", log_file_path)
# List all .R files recursively
r_files <- list.files(path = dir_path, pattern = "\\.R$", recursive = TRUE, full.names = TRUE)
# Create dataframe to write checking result
if (!file.exists(checked_source_path)) {
df <- data.frame(path = c("Test"), isGood = c(TRUE))
for (r_file in r_files) {
new_row <- data.frame(
path = r_file,
isGood = FALSE
)
df <- rbind(df, new_row)
}
write.csv(df, file = checked_source_path, row.names = FALSE)
checking_files <- r_files
} else {
df <- read.csv(checked_source_path)
filtered_df <- df %>% filter(isGood == TRUE)
checking_files <- r_files[!r_files %in% filtered_df$path]
}
checking_files <- checking_files[-1]
checking_files
# install.packages("dplyr")
# install.packages("dfoptim")
# install.packages("lsa")
# install.packages("xtable")
# install.packages("rjags")
# install.packages("cubature")
# install.packages("circular")
# install.packages("ggplot2")
# install.packages("mixtools")
# Load the necessary library
library(dplyr)
# Ignore warnings
#options(warn = -1)
# Parameters
target <- "ComputationalModeling"
base_dir_path <- "/Users/seojin/Desktop/ComputationalCognitiveModeling"
test_code_dir_path <- "/Users/seojin/Desktop/ComputationalCognitiveModeling/TestCodes"
dir_path <- paste0(base_dir_path, "/", target)
log_file_path <- paste0(test_code_dir_path, "/" , paste0(target, "_log.txt"))
checked_source_path <- paste0(test_code_dir_path, "/" , paste0(target, "_checked.csv"))
plot_dir_path <- paste0(test_code_dir_path, "/" , target)
# Log
file.remove(log_file_path)
writeLines("Start testing", log_file_path)
# List all .R files recursively
r_files <- list.files(path = dir_path, pattern = "\\.R$", recursive = TRUE, full.names = TRUE)
# Create dataframe to write checking result
if (!file.exists(checked_source_path)) {
df <- data.frame(path = c("Test"), isGood = c(TRUE))
for (r_file in r_files) {
new_row <- data.frame(
path = r_file,
isGood = FALSE
)
df <- rbind(df, new_row)
}
write.csv(df, file = checked_source_path, row.names = FALSE)
checking_files <- r_files
} else {
df <- read.csv(checked_source_path)
filtered_df <- df %>% filter(isGood == TRUE)
checking_files <- r_files[!r_files %in% filtered_df$path]
}
checking_files <- checking_files[-1]
# Function to save plots
save_all_plots <- function(plot_dir, plot_count) {
plot_file <- file.path(plot_dir, paste0("plot_", plot_count, ".png"))
dev.copy(png, filename = plot_file)
dev.off()
}
# Get experiment directory paths
experiment_dir_paths <- unique(dirname(checking_files))
# Loop all experiment directory and run source code.
for (experiment_dir_path in experiment_dir_paths) {
setwd(experiment_dir_path)
r_files <- list.files(path = experiment_dir_path, pattern = "\\.R$", full.names = TRUE)
r_files <- r_files[r_files %in% checking_files]
for (r_file in r_files) {
# Get the R file name from the full path
file_name <- tools::file_path_sans_ext(basename(r_file))
# Define the path to save the plots
plot_dir <- file.path(plot_dir_path, "plots", file_name)
if (!dir.exists(plot_dir)) {
dir.create(plot_dir, recursive = TRUE)  # Ensure all directories in the path are created
}
# Initialize log_conn to avoid reference errors
log_conn <- file(log_file_path, open = "a")
tryCatch({
# Redirect both standard output and error to the log file
sink(log_conn, append = TRUE)
sink(log_conn, append = TRUE, type = "message")
cat(paste("\nSource code is on checking:", r_file))
plot_count <- 1  # Initialize plot count
# Run the R script
source(r_file)
# Save each plot generated during the script execution
if (dev.cur() > 1) {  # If there is an active plot
save_all_plots(plot_dir, plot_count)
plot_count <- plot_count + 1
}
isGood <<- TRUE
}, error = function(e) {
# Error handling, writing directly to the log file
cat("Error in source:", r_file, "\n", conditionMessage(e), "\n", file = log_file_path, append = TRUE)
isGood <<- FALSE
}, finally = {
# Ensure the sinks are reset and the connection is closed
sink()  # Reset the standard output back to the console
sink(type = "message")  # Reset the standard error output back to the console
close(log_conn)  # Close the log file connection
# Write the updated data frame back to the CSV file
df <- read.csv(checked_source_path)
df[df$path == r_file, "isGood"]  <- isGood
write.csv(df, file = checked_source_path, row.names = FALSE)
})
}
}
install.packages("lme4")
require(lme4)
n <- 10
sigtrials <- noistrials <- 100
ntrials <- sigtrials + noistrials
h <- rbinom(n,sigtrials, .60)
f <- rbinom(n,noistrials,.11)
subj <- rep(c(1:n),each=ntrials)
stim <- rep(c(rep(1,sigtrials),rep(0,noistrials)),n)
resp <- as.vector( vapply(h,FUN=function(x)
as.integer(c(rep(1,x),
rep(0,ntrials-x))),
integer(ntrials))
+
vapply(f,FUN=function(x)
as.integer(c(rep(0,sigtrials),
rep(1,x),rep(0,noistrials-x))),
integer(ntrials))  )
#model with intercept = z(FA) default
mlhierarchSDT <- glmer(resp ~ stim + (1+stim|subj), family=binomial(link = "probit"))
summary(mlhierarchSDT)
#reparameterize so intercept = c
reparmstim <- cbind(-1,stim)
colnames(reparmstim) <- c("_c", "_d'")
mlhierarchSDTc <- glmer(resp ~ reparmstim-1 + (1+stim|subj), family=binomial(link = "probit"))
summary(mlhierarchSDTc)
#reparameterize so b is not highly correlated with d'
rmstim <- stim-.5
reparmstim <- cbind(-1,rmstim)
colnames(reparmstim) <- c("_b", "_d'")
mlhierarchSDTrp <- glmer(resp ~ reparmstim-1 + (1+rmstim|subj), family=binomial(link = "probit"))
summary(mlhierarchSDTrp)
install.packges("R.utils")
install.packages("R.utils")
library(R.utils)
library(rjags)
grabfun<-function(x,p,var) {return(x[x$subj==p,var])}
itcdata<-read.table("hierarchicalITC.dat",header=TRUE)
subjects <- unique(itcdata$subj)
ntrials  <- dim(itcdata)[1]/length(unique(itcdata$subj))
nsubj    <- length(unique(itcdata$subj))
delays4A  <- t(vapply(subjects,FUN=function(x) grabfun(itcdata,x,"DA"),integer(ntrials)))
delays4B  <- t(vapply(subjects,FUN=function(x) grabfun(itcdata,x,"DB"),integer(ntrials)))
amounts4A <- t(vapply(subjects,FUN=function(x) grabfun(itcdata,x,"A"),integer(ntrials)))
amounts4B <- t(vapply(subjects,FUN=function(x) grabfun(itcdata,x,"B"),integer(ntrials)))
responses <- t(vapply(subjects,FUN=function(x) grabfun(itcdata,x,"R"),integer(ntrials)))
#initialize model for JAGS
hierITC <- jags.model("hierarchicalITC.j",
data = list("nsubj"=nsubj,
"DA"=delays4A,
"DB"=delays4B,
"A"=amounts4A,
"B"=amounts4B,
"T"=ntrials,
"R"=responses),
n.chains=4)
# burnin
update(hierITC,n.iter=1000)
# perform MCMC
parameters <- c("k", "alpha", "groupkmu", "groupksigma", "groupALPHAmu", "groupALPHAsigma",
"VA","VB","P","DB")
mcmcfin<-coda.samples(hierITC,parameters,5000)
summary(mcmcfin)
library(rjags)
# initialize the data
consistent    <- c( 78, 70, 7, 15)
inconsistent  <- c(102, 55, 40, 53)
neutral       <- c( 63, 45, 13, 21)
Nsubj         <- c(170, 250, 142)
#define JAGS model
noconflict <- jags.model("wagenaar.j",
data = list("Nsubj"=Nsubj,
"consistent"=consistent,
"inconsistent"=inconsistent,
"neutral"=neutral),
n.chains=3)
# Load the necessary library
library(dplyr)
# Ignore warnings
#options(warn = -1)
# Parameters
target <- "ComputationalModeling"
base_dir_path <- "/Users/seojin/Desktop/ComputationalCognitiveModeling"
test_code_dir_path <- "/Users/seojin/Desktop/ComputationalCognitiveModeling/TestCodes"
dir_path <- paste0(base_dir_path, "/", target)
log_file_path <- paste0(test_code_dir_path, "/" , paste0(target, "_log.txt"))
checked_source_path <- paste0(test_code_dir_path, "/" , paste0(target, "_checked.csv"))
plot_dir_path <- paste0(test_code_dir_path, "/" , target)
# Log
file.remove(log_file_path)
writeLines("Start testing", log_file_path)
# List all .R files recursively
r_files <- list.files(path = dir_path, pattern = "\\.R$", recursive = TRUE, full.names = TRUE)
# Create dataframe to write checking result
if (!file.exists(checked_source_path)) {
df <- data.frame(path = c("Test"), isGood = c(TRUE))
for (r_file in r_files) {
new_row <- data.frame(
path = r_file,
isGood = FALSE
)
df <- rbind(df, new_row)
}
write.csv(df, file = checked_source_path, row.names = FALSE)
checking_files <- r_files
} else {
df <- read.csv(checked_source_path)
filtered_df <- df %>% filter(isGood == TRUE)
checking_files <- r_files[!r_files %in% filtered_df$path]
}
checking_files <- checking_files[-1]
# Function to save plots
save_all_plots <- function(plot_dir, plot_count) {
plot_file <- file.path(plot_dir, paste0("plot_", plot_count, ".png"))
dev.copy(png, filename = plot_file)
dev.off()
}
# Get experiment directory paths
experiment_dir_paths <- unique(dirname(checking_files))
# Loop all experiment directory and run source code.
for (experiment_dir_path in experiment_dir_paths) {
setwd(experiment_dir_path)
r_files <- list.files(path = experiment_dir_path, pattern = "\\.R$", full.names = TRUE)
r_files <- r_files[r_files %in% checking_files]
for (r_file in r_files) {
# Get the R file name from the full path
file_name <- tools::file_path_sans_ext(basename(r_file))
# Define the path to save the plots
plot_dir <- file.path(plot_dir_path, "plots", file_name)
if (!dir.exists(plot_dir)) {
dir.create(plot_dir, recursive = TRUE)  # Ensure all directories in the path are created
}
# Initialize log_conn to avoid reference errors
log_conn <- file(log_file_path, open = "a")
tryCatch({
# Redirect both standard output and error to the log file
sink(log_conn, append = TRUE)
sink(log_conn, append = TRUE, type = "message")
cat(paste("\nSource code is on checking:", r_file))
plot_count <- 1  # Initialize plot count
# Run the R script
source(r_file)
# Save each plot generated during the script execution
if (dev.cur() > 1) {  # If there is an active plot
save_all_plots(plot_dir, plot_count)
plot_count <- plot_count + 1
}
isGood <<- TRUE
}, error = function(e) {
# Error handling, writing directly to the log file
cat("Error in source:", r_file, "\n", conditionMessage(e), "\n", file = log_file_path, append = TRUE)
isGood <<- FALSE
}, finally = {
# Ensure the sinks are reset and the connection is closed
sink()  # Reset the standard output back to the console
sink(type = "message")  # Reset the standard error output back to the console
close(log_conn)  # Close the log file connection
# Write the updated data frame back to the CSV file
df <- read.csv(checked_source_path)
df[df$path == r_file, "isGood"]  <- isGood
write.csv(df, file = checked_source_path, row.names = FALSE)
})
}
}
#plot some vwm data
source("MixModel.R")
system_info <- Sys.info() # Get system information
os <- system_info["sysname"] # Extract and print the operating system
os
# install.packages("dplyr")
# install.packages("dfoptim")
# install.packages("lsa")
# install.packages("xtable")
# install.packages("rjags")
# install.packages("cubature")
# install.packages("circular")
# install.packages("ggplot2")
# install.packages("mixtools")
# install.packages("lme4")
# install.packages("R.utils")
# Load the necessary library
library(dplyr)
# Ignore warnings
#options(warn = -1)
# Parameters
target <- "ComputationalModeling"
base_dir_path <- "/Users/seojin/Desktop/ComputationalCognitiveModeling"
test_code_dir_path <- "/Users/seojin/Desktop/ComputationalCognitiveModeling/TestCodes"
dir_path <- paste0(base_dir_path, "/", target)
log_file_path <- paste0(test_code_dir_path, "/" , paste0(target, "_log.txt"))
checked_source_path <- paste0(test_code_dir_path, "/" , paste0(target, "_checked.csv"))
plot_dir_path <- paste0(test_code_dir_path, "/" , target)
# Log
file.remove(log_file_path)
writeLines("Start testing", log_file_path)
# List all .R files recursively
r_files <- list.files(path = dir_path, pattern = "\\.R$", recursive = TRUE, full.names = TRUE)
# Create dataframe to write checking result
if (!file.exists(checked_source_path)) {
df <- data.frame(path = c("Test"), isGood = c(TRUE))
for (r_file in r_files) {
new_row <- data.frame(
path = r_file,
isGood = FALSE
)
df <- rbind(df, new_row)
}
write.csv(df, file = checked_source_path, row.names = FALSE)
checking_files <- r_files
} else {
df <- read.csv(checked_source_path)
filtered_df <- df %>% filter(isGood == TRUE)
checking_files <- r_files[!r_files %in% filtered_df$path]
}
checking_files <- checking_files[-1]
# Function to save plots
save_all_plots <- function(plot_dir, plot_count) {
plot_file <- file.path(plot_dir, paste0("plot_", plot_count, ".png"))
dev.copy(png, filename = plot_file)
dev.off()
}
# Get experiment directory paths
experiment_dir_paths <- unique(dirname(checking_files))
# Loop all experiment directory and run source code.
for (experiment_dir_path in experiment_dir_paths) {
setwd(experiment_dir_path)
r_files <- list.files(path = experiment_dir_path, pattern = "\\.R$", full.names = TRUE)
r_files <- r_files[r_files %in% checking_files]
for (r_file in r_files) {
# Get the R file name from the full path
file_name <- tools::file_path_sans_ext(basename(r_file))
# Define the path to save the plots
plot_dir <- file.path(plot_dir_path, "plots", file_name)
if (!dir.exists(plot_dir)) {
dir.create(plot_dir, recursive = TRUE)  # Ensure all directories in the path are created
}
# Initialize log_conn to avoid reference errors
log_conn <- file(log_file_path, open = "a")
tryCatch({
# Redirect both standard output and error to the log file
sink(log_conn, append = TRUE)
sink(log_conn, append = TRUE, type = "message")
cat(paste("\nSource code is on checking:", r_file))
plot_count <- 1  # Initialize plot count
# Run the R script
source(r_file)
# Save each plot generated during the script execution
if (dev.cur() > 1) {  # If there is an active plot
save_all_plots(plot_dir, plot_count)
plot_count <- plot_count + 1
}
isGood <<- TRUE
}, error = function(e) {
# Error handling, writing directly to the log file
cat("Error in source:", r_file, "\n", conditionMessage(e), "\n", file = log_file_path, append = TRUE)
isGood <<- FALSE
}, finally = {
# Ensure the sinks are reset and the connection is closed
sink()  # Reset the standard output back to the console
sink(type = "message")  # Reset the standard error output back to the console
close(log_conn)  # Close the log file connection
# Write the updated data frame back to the CSV file
df <- read.csv(checked_source_path)
df[df$path == r_file, "isGood"]  <- isGood
write.csv(df, file = checked_source_path, row.names = FALSE)
})
}
}
system_info <- Sys.info() # Get system information
os <- system_info["sysname"] # Extract and print the operating system
if (system_info["sysname"] == "Windows") {
windows()
} else {
# Run a different function or do nothing for non-Windows OS
# library(grDevices)
# x11(width = 10, height = 5)
quartz(width = 10, height = 5)
}
